{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Python and Data Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we've used functions and statistical tools in Microsoft Excel to process data to better understand trends, outliers, predictions, and groupings in open data. To better handle, work more quickly with, and process faster data in this course, we'll use the [Python](https://www.python.org) programming language in [Jupyter Lab notebooks](https://jupyter.org). There are many applications for the tools we'll discuss and use in class and for assignments, however, you'll only need to be responsible for how Jupyter and Python relate to the specific data analysis tools we cover in this course. There are several online (both free and paid) [online courses](https://www.codecademy.com/learn/paths/analyze-data-with-python), [video tutorials](https://www.udemy.com/topic/pandas/), and [e-books](https://github.com/jakevdp/PythonDataScienceHandbook) that can help support additional applications in automation, data analysis, and predictive modeling if you wish to broaden your understanding and use cases for Python and data analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Convention for Jupyter Notebooks for Business Analytics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all Jupyter notebooks or code files in this class, please use the naming convention:\n",
    "\n",
    "__year-month-day-github_username-short-descriptive-title-for-notebook__\n",
    "\n",
    "This will help you, and anyone else reading your documents, know when you created the document, know who initially created the document if they want to reach out or ask specific questions, and understand a bit about what's inside the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Jupyter Notebooks and Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to write and deploy code, similar to how there are several ways to write and read text documents (Microsoft Word, Pages, Google Docs, Text files, PDF documents, etc.). Jupyter Lab is nice to work with when you're exploring datasets because you can run different iterations of your analysis without needing to run your entire code, you can \"de-bug\" as you iterate on your analysis, and you can incorporate code, visualizations, formatted plain text, and images and hyperlinks in the same document, which can be useful for your own personal documentation as well as sharing your work with others. \n",
    "\n",
    "Jupyter is also [rising in popularity](https://www.nature.com/articles/d41586-018-07196-1) among scientists because of its ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write text and code in Jupyter notebooks in different cells. Plain text cells are designated as __[Markdown](https://nbsphinx.readthedocs.io/en/0.4.3/markdown-cells.html)__ cells and use the same language/formatting that we've covered in GitHub README.md documents. __[Code](https://nbsphinx.readthedocs.io/en/0.4.3/code-cells.html)__ cells interpret and run Python code because we designated this as a Python notebook on launch. __[Raw cells](https://nbsphinx.readthedocs.io/en/0.4.3/raw-cells.html)__ allow you to change the formatting of the cells to HTML, reST, or LaTex, which isn't applicable for what we'll cover in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'or, you can\\nwrite a string of notes\\nwithin three single or double\\nquotation marks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In \"Code\" cells, we can write Python code\n",
    "# although we can use Markdown cells to write text, it may be useful to write non-python notes in the Code cells as well\n",
    "# We can write notes with either a hashtag in front of the line of code (which means you need a \n",
    "# hashtag in front of every line)\n",
    "\n",
    "\"\"\"or, you can\n",
    "write a string of notes\n",
    "within three single or double\n",
    "quotation marks\"\"\"\n",
    "\n",
    "# to \"run\" any Jupyter cell, you'll need to hold down the \"Shift\" key while pressing \"Return/En\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change a cell from Markdown to Code, you can either click on the cell and change the type from the dropdown menu at the top right of the menu bar. You can also use hotkeys to do this by pressing the \"Escape\" key, then \"M\" to change the cell to a Markdown, or pressing the \"Escape\" key, then \"Y\" to change the cell to a Code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add additional cells in your notebook, you can click the \"+\" button on the top left of the menu bar. You can also use hotkeys to add cells above (ESC, then \"A\") or below (ESC, then \"B\") your active cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebooks will save every so often on their own every 120 seconds ([which you can change on your own](https://support.anaconda.com/hc/en-us/articles/360023997353-Change-default-autosave-time-in-notebooks)). You can also save notebook checkpoints, which can be helpful to revert back to the last manually-saved version of your notebook (note though, once you revert back to a checkpoint, you can't undo this action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is increasing in popularity and [\"becoming the world's most popular coding language\"](https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language) due to it's versatility and simplicity. There may be different computer coding languages that are better suited for more specific statistical analysis (R, STATA) or much larger datasets (SAS), but Python's open source community, flexibility, and ease to learn and implement make it a good tool for us to utilize in our data analysis with larger datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing Python computer code is like writing a food recipe. We are essentially telling our computer what kind of ingredients and tools (packages and libraries) we need to make the food (carry out our data analysis or other actions). However, unlike humans following a recipe for cake, computers cannot necessarily intuit what a typo or mistake might actually mean. \n",
    "\n",
    "If we read a recipe for cake that says \"1 cup salt\" or even \"1 cup suger,\" we can probably guess that this is a typo and that this might mean \"1 cup sugar.\" However, our Jupyter notebook wil not be able to \"guess\" what we meant if we mis-type something, so capitalization, spacing, and characters matter __a lot__ in our computer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Pandas & Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're mainly going to use Python for data analysis and geospatial analysis in this class. In our \"Python recipe\" the first thing we'll need to do is import the libraries for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can do any data analysis, we need to tell our computer code what we're going to be doing and with what tools. __Pandas__ (which stands for Panel Data--not the animal) is a library that has a set of functions that allow us to interact with and manipulate our data, and __pandas-profiling__ will allow us to get some high-level data about our data without much work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will allow us to work with data similar to an Excel workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to import the data for our analysis. In this example, we'll use the Uber Movement data that we used at the beginning of the semester. Because we've uploaded this to [GitHub as a CSV file](https://github.com/jhu-business-analytics/big-picture-data-analysis), we can import this data in two ways with pandas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use read_csv (or read_excel) to import data on a local file\n",
    "# this is called a pandas data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can preview the first five rows of this data set with df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import this directly from GitHub, we use the link to the raw CSV file data instead of the local path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we preview the data, we see that this is exactly the same as our exported file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Note: since these data frames are the same, we can use either in our subsequent analysis. I will use the local version in all examples*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding our Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start cleaning or conducting analysis with our data, we'll want to get an idea of what's in our data and what we might be able to do with it immediately \"out of the box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info() tells us about the data types and number of items in each column in our dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there are 5 different data types that we'll work with:\n",
    "1. integers (int) - these are numbers that don't have a decimal.\n",
    "2. floats (float) - these are numbers that have a decimal. We can perform math functions with integers & integers and integers & floats\n",
    "3. strings (str) - or objects; these are any series of characters, which can be numbers, letters, spaces, special characters, or any combination of those. Strings are delimited with either single quotes ('') or double quotes (\"\")\n",
    "4. Boolean (bool) - data types that are either True or False. Boolean data types are used a lot in Python logic expressions\n",
    "5. datetime (datetime) - for dates and times. Datetime objects allow us to perform calculations with other dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also quickly get an idea of what's happening in the integer/float columns in our dataframe with df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect of data analysis is *cleaning* the data. This means we need to make sure that it's usable for future data merging and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we cleaned this data in Excel, we wanted to:\n",
    "1. Create a new column that showed our Mean Travel Time in minutes instead of seconds\n",
    "2. Separate out the dates from the unnecessary words/characters in the Date Range column so that we could sort things by date\n",
    "3. Identify the day of the week and day of the week name for each date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we manipulate data in our data frame columns, we'll identify the data frame and column by:\n",
    "\n",
    "__df_name[\"column_name\"] = action_on_column_or_subset_of_column__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a new column for Mean Travel Time in Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Mean Travel Time into Minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the number in Minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Separate out dates from unnecessary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate our values in the Date Range column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Identify day of week and day of week name for each date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Date Range column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the name of the week for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the name of the week for each date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we run `df.describe()` and `df.info()`, we'll get a better idea of what our data is telling us: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis with Uber Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we cleaned our data, we wanted to look at some big-picture data aggregation to look at the average travel time per day, the percentage of time traveled on each week day, and the average travel time per date. We'll aggregate this information with a pandas groupby aggregation.\n",
    "\n",
    "In a pandas groupby, we can perform calculations on a specific group of data within our dataset and then apply these calculations to the current dataframe (as a new column) or create a new dataframe with grouped and aggregated information.\n",
    "In our example, we'll use .agg to aggregate values in our dataset based on a chosen group (Day Name) by following the following the following convention:\n",
    "\n",
    "`new_dataframe_name = old_data_frame_name.groupby(\"column_we_want_to_group_values_by\")[\"column_we_want_to_perform_group_calculation_on\"].agg([\"function_we_want_to_perform\"]).reset_index()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data into a new dataframe that only lists the column(s) we identify in the groupby and the aggregating function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also still create pivot tables in Python with the following convention:\n",
    "\n",
    "`new_dataframe = pd.pivot_table(old_dataframe, values = columns_we_want_in_values_fields_of_pivot_table, \n",
    "                                       index = columns_we_want_as_row_fields, \n",
    "                                       columns = columns_we_want_as_column_fields, \n",
    "                                       aggfunc = np.function_we_want_to_perform_on_values).reset_index()\n",
    "                                       `\n",
    "                                       \n",
    "If we want to use more than one column in the values, index, or column fields, then we need to make them into a list. For example, if we wanted to use Day Name and Date Range as our row fields, we would write `index = [\"Day Name\", \"Date Range\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table with data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also sort our data by the day of the week name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
